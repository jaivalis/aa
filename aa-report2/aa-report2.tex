\documentclass[11pt]{article}
\usepackage{array}
\usepackage{tabularx}
\usepackage{graphicx}
\title{
	\textbf{Autonomous Agents Assignment 2}
}

\author{Tobias Stahl \\ 10528199 \and Spyros Michaelides \\ 10523316 \and Ioannis Giounous Aivalis \\ 10524851 \and Francesco Stablum \\ 6200982}
\usepackage{graphicx}
\begin{document}

\maketitle




\section{Introduction}



\section{Q-Learning}
The initial exercise of this lab assignment is to implement Q-learning the temporal-difference (TD) learning algorithm. This algorithm is to be used by the predator agent to catch the prey.



\subsection{Summary}
Q-learning is an off-policy TD control algorithm. An off-policy TD algorithm is one in which the estimated value functions can be updated using hypothetical actions, without having actually executed the actions themselves. Using this approach the algorithm can separate exploration from control, meaning the agent could learn through from the environment without necessarily having had the explicit experience.
Q-learning 


\begin{thebibliography}{2}

\bibitem{1} http://http://www.cse.unsw.edu.au/~cs9417ml/RL1/tdlearning.html

\bibitem{2} http://webdocs.cs.ualberta.ca/~sutton/book/ebook/node65.html


\end{thebibliography}


\end{document}